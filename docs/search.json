[
  {
    "objectID": "posts/non-tech/الهشاشة-النفسية.html",
    "href": "posts/non-tech/الهشاشة-النفسية.html",
    "title": "الهشاشة النفسية: إسماعيل عرفة",
    "section": "",
    "text": "من الواضح جدا انتشار ظاهرة الهشاشة النفسية وتضخيم المعاناة والألم دون أدني عقلانية أو مواجهة للأمور التي ف الغالب تكون تافهة ولا ترقي لمستوي المعاناة المتواجدة.\nمفهوم تضخيم المعاناة (pain catastrophizing) في علم النفس يعبر عن حالة شعورية تعتري الإنسان عند وقوعه في مشكلة ما ، تجعله هذه الحالة يظن أن المشكلة أكبر من قدرته علي التحمل ويتخللها وصفه للمشكلة بأوصاف أكبر من حجم المشكلة الحقيقي، تؤدي في النهاية لاستسلام الشخص للشعور بالضياع وعدم قدرته علي مواجهة الحياة.\nمن الواضح جدًا أن الجيل الحالي يتميز بخصلة غريبة ألا وهي أنك تجد شابا في عمر ال 25 وعمره العقلي ومستواه الإجتماعي الفكري لا يتجاوز سن المراهقة، فهل أصبح سن المراهقة حقًا حتى ال 25 ؟\nإنطلاقًا مما سبق، جري تسمية الجيل الحالي جيل رقائق الثلج وترجه هذه التسمية إلي سببين:\n\nأولهما: رقائق الثلج هشة جدًا لا تتحمل أي ضغط إذا تعرضت ﻷي ظرف خارجي.\nثانيهما : رقائق الثلج مختلفة عن بعضها البعض كما هو الحال مع جيل اليوم حيث يشعر كل فرد فيه بتميزه عن غيره واستحقاقه لما هو أفضل ويتم تغذيته بأفكار الريادة والاستحقاقية أي أن له توقعات\nعالية من جميع من حوله ويتوقع أن يعامله الجميع بحفاوة.\n\n\nنسيم طالب: يولد الإنسان منذ صغره ولديه مرونة نفسية تساعده علي التكيف والتعامل مع المؤثرات الخارجية، ينقسم الناس في تكيفهم وتعاملهم إلي ثلاثة أنواع: ضعيف، قوي، غير قابل للكسر.\nالسبب في اختلاف استجابة الجيل الحالي عن آبائهم مثلا يقبع بسبب التنشئة والتربية لما تعرضت له الأجيال السابقة من ظروف أجبرتها علي تكوين شخصية قابلة للتعامل مع المشكلات وحلها.\nيلجأ الشباب في الجيل الحالي إلي الشعور بالإهانة والخوض في شخصية الضحية من أضغر كلمة، حتي صرنا نسمع عن حملات لمحاربة مفهوم التنمر، وهو مفهوم حقيقي موجود لكنه لم يكن أبدًا بهذا التضخيم الموجود له وهو ما أدي إلي خلل في معرفة إن كانت المشكلة عادية أو أنها تنمرًا علي سبيل المثال.\nما لا يقتلك يجعلك أقوي ، علي المرء أن يتقبل وقوعه فى المشكلات أو الحزن ويحاول جاهدًا التغلب عليها.\nالحزن جزء أساسي من الوجود الإنساني، ويجب معاملته كوسيلة فعالة لبناء إنسان قادر علي مواجهة الصعوبات والتغلب عليها، بمعني آخر، هو حالة لا بد منها لا يجب الفرار منها بالميل إلي شخصية الضحية بل بالعمل علي مواجهة ماسببها ومحاولة إيجاد حلول له.\n\n\n\n\nيؤدي الدلال المتزايد وعدم تحمل المسئولية إلي إنتاج فرد غير قادر علي تحمل مشقات الحياة مهما كانت بسيطة ومهما كانت الضغوطات الوااقعة عليه.\nتربية الآباء ﻷبنائهم في هذا الجيل وإصباغ صبغة من الحماية الزائدة عليهم أدت في النهاية لعدم تحمل الأبناء أيًا من مشقات الحياة، أنتجت جيلا هشًا متأخرًا عمن سبقوه من الأجيال من حيث الوعي المعرفي والقدرة علي التحمل والمرونة.\nبعض الدراسات أثيتت أن القشرة الأمامية للمخ لا تنضج تي سن ال 25، وهو إن كان صحيحًا فإنه يغفل فكرة أن المخ لدن ومرون طبقًا للتجارب التي يعيشها الإنسان.\nهناك الكثير من الفوائد التي تنتج من تدريب أنفسنا علي المرونة النفسية:\n\nتحسن الصحة النفسية والذهنية.\nتحسن الأداء الإدراكي المعرفي.\nالحفاظ علي الهدوء الداخلي.\nالقدرة علي الإرتداد سريعًا بعد الهزائم والإنتكاسات.\n\n\n\n\n\n\nأهم عامل يمكنك من بناء نفس مرنة هو تعويدها علي المرونة من خلال خوض غمار الحياة الحقيقية، لا حياة وسائل التواصل الإجتماعي، وتربية النفس علي تحمل أخطائها والتعامل معها ومحاولة إصلاحها.\nهذا السبيل وحده هو الذي يمكن الإنسان من بناء نفس مرنة لا تتأثر بما يقوله الناس عنها ولا ترى عيبًا في الإعتراف بالتقصير مع الحرص علي معالجة الخطأ والتعلم من المواقف.\nكلمة السر هي المناعة: يبنغي أن يكون الإنسان مناعة ضد كلام الناس، مشاكل الحياة وتقلباتها، ونعودها علي تقبل المكابدة والألم مع الوضع في الإعتبار أن هذا الأمر ليس متفردًا للشخص بل هو الطبيعي في هذه الحياةالمليئة بكثير من الضغوطات.\nتوطين النفس علي الصبر علي المكاره، والإلتجاء إلي الله مع استنفاذ الوسع في الأخذ بالأسباب هو الطريق لخروج الإنسان من ضيق المشاكل وتحمله علي الإنشغال بالمهام الكبري."
  },
  {
    "objectID": "posts/non-tech/الهشاشة-النفسية.html#الفصل-الأول-جيل-رقائق-الثلج",
    "href": "posts/non-tech/الهشاشة-النفسية.html#الفصل-الأول-جيل-رقائق-الثلج",
    "title": "الهشاشة النفسية: إسماعيل عرفة",
    "section": "",
    "text": "من الواضح جدا انتشار ظاهرة الهشاشة النفسية وتضخيم المعاناة والألم دون أدني عقلانية أو مواجهة للأمور التي ف الغالب تكون تافهة ولا ترقي لمستوي المعاناة المتواجدة.\nمفهوم تضخيم المعاناة (pain catastrophizing) في علم النفس يعبر عن حالة شعورية تعتري الإنسان عند وقوعه في مشكلة ما ، تجعله هذه الحالة يظن أن المشكلة أكبر من قدرته علي التحمل ويتخللها وصفه للمشكلة بأوصاف أكبر من حجم المشكلة الحقيقي، تؤدي في النهاية لاستسلام الشخص للشعور بالضياع وعدم قدرته علي مواجهة الحياة.\nمن الواضح جدًا أن الجيل الحالي يتميز بخصلة غريبة ألا وهي أنك تجد شابا في عمر ال 25 وعمره العقلي ومستواه الإجتماعي الفكري لا يتجاوز سن المراهقة، فهل أصبح سن المراهقة حقًا حتى ال 25 ؟\nإنطلاقًا مما سبق، جري تسمية الجيل الحالي جيل رقائق الثلج وترجه هذه التسمية إلي سببين:\n\nأولهما: رقائق الثلج هشة جدًا لا تتحمل أي ضغط إذا تعرضت ﻷي ظرف خارجي.\nثانيهما : رقائق الثلج مختلفة عن بعضها البعض كما هو الحال مع جيل اليوم حيث يشعر كل فرد فيه بتميزه عن غيره واستحقاقه لما هو أفضل ويتم تغذيته بأفكار الريادة والاستحقاقية أي أن له توقعات\nعالية من جميع من حوله ويتوقع أن يعامله الجميع بحفاوة.\n\n\nنسيم طالب: يولد الإنسان منذ صغره ولديه مرونة نفسية تساعده علي التكيف والتعامل مع المؤثرات الخارجية، ينقسم الناس في تكيفهم وتعاملهم إلي ثلاثة أنواع: ضعيف، قوي، غير قابل للكسر.\nالسبب في اختلاف استجابة الجيل الحالي عن آبائهم مثلا يقبع بسبب التنشئة والتربية لما تعرضت له الأجيال السابقة من ظروف أجبرتها علي تكوين شخصية قابلة للتعامل مع المشكلات وحلها.\nيلجأ الشباب في الجيل الحالي إلي الشعور بالإهانة والخوض في شخصية الضحية من أضغر كلمة، حتي صرنا نسمع عن حملات لمحاربة مفهوم التنمر، وهو مفهوم حقيقي موجود لكنه لم يكن أبدًا بهذا التضخيم الموجود له وهو ما أدي إلي خلل في معرفة إن كانت المشكلة عادية أو أنها تنمرًا علي سبيل المثال.\nما لا يقتلك يجعلك أقوي ، علي المرء أن يتقبل وقوعه فى المشكلات أو الحزن ويحاول جاهدًا التغلب عليها.\nالحزن جزء أساسي من الوجود الإنساني، ويجب معاملته كوسيلة فعالة لبناء إنسان قادر علي مواجهة الصعوبات والتغلب عليها، بمعني آخر، هو حالة لا بد منها لا يجب الفرار منها بالميل إلي شخصية الضحية بل بالعمل علي مواجهة ماسببها ومحاولة إيجاد حلول له.\n\n\n\n\nيؤدي الدلال المتزايد وعدم تحمل المسئولية إلي إنتاج فرد غير قادر علي تحمل مشقات الحياة مهما كانت بسيطة ومهما كانت الضغوطات الوااقعة عليه.\nتربية الآباء ﻷبنائهم في هذا الجيل وإصباغ صبغة من الحماية الزائدة عليهم أدت في النهاية لعدم تحمل الأبناء أيًا من مشقات الحياة، أنتجت جيلا هشًا متأخرًا عمن سبقوه من الأجيال من حيث الوعي المعرفي والقدرة علي التحمل والمرونة.\nبعض الدراسات أثيتت أن القشرة الأمامية للمخ لا تنضج تي سن ال 25، وهو إن كان صحيحًا فإنه يغفل فكرة أن المخ لدن ومرون طبقًا للتجارب التي يعيشها الإنسان.\nهناك الكثير من الفوائد التي تنتج من تدريب أنفسنا علي المرونة النفسية:\n\nتحسن الصحة النفسية والذهنية.\nتحسن الأداء الإدراكي المعرفي.\nالحفاظ علي الهدوء الداخلي.\nالقدرة علي الإرتداد سريعًا بعد الهزائم والإنتكاسات.\n\n\n\n\n\n\nأهم عامل يمكنك من بناء نفس مرنة هو تعويدها علي المرونة من خلال خوض غمار الحياة الحقيقية، لا حياة وسائل التواصل الإجتماعي، وتربية النفس علي تحمل أخطائها والتعامل معها ومحاولة إصلاحها.\nهذا السبيل وحده هو الذي يمكن الإنسان من بناء نفس مرنة لا تتأثر بما يقوله الناس عنها ولا ترى عيبًا في الإعتراف بالتقصير مع الحرص علي معالجة الخطأ والتعلم من المواقف.\nكلمة السر هي المناعة: يبنغي أن يكون الإنسان مناعة ضد كلام الناس، مشاكل الحياة وتقلباتها، ونعودها علي تقبل المكابدة والألم مع الوضع في الإعتبار أن هذا الأمر ليس متفردًا للشخص بل هو الطبيعي في هذه الحياةالمليئة بكثير من الضغوطات.\nتوطين النفس علي الصبر علي المكاره، والإلتجاء إلي الله مع استنفاذ الوسع في الأخذ بالأسباب هو الطريق لخروج الإنسان من ضيق المشاكل وتحمله علي الإنشغال بالمهام الكبري."
  },
  {
    "objectID": "posts/non-tech/الهشاشة-النفسية.html#الفصل-الثاني-هوس-الطب-النفسي",
    "href": "posts/non-tech/الهشاشة-النفسية.html#الفصل-الثاني-هوس-الطب-النفسي",
    "title": "الهشاشة النفسية: إسماعيل عرفة",
    "section": "الفصل الثاني: هوس الطب النفسي",
    "text": "الفصل الثاني: هوس الطب النفسي\n\n\nالصدمات النفسية جزء لا يتجزأ من الحياة. هذا هو ديدن الحياة بل ديدن النفس البشرية ذاتها والتي تتبدل أحوالها ويصيبها ما يصيبها بمرور المواقف والصراعات اليومية، فتجد الكسل تارة والنشاط تارة أخري، والحياة أيضًا لها حزنها وفرحها.\nتملي علينا الظروف المعيشية الطبيعية أحيانًا مجموعة ضغوطات نستجيب لها وفقًا لميكانيزمات المواجهة الخاصة بنا، فكلما زادت مرونة الشخص النفسية وقدرته علي مصارعة هذه التحديات كلما كانت العواقب أقل وطئة ، ثم ما يلبث أن يبحث الشخص عن وسيلة للدعم تختلف بإختلاف طبيعته، فمن الناس من يحبذ ممارسة الرياضة، ومنهم من يحبذ البوح لأحد المقربين.\nالمشكلة اليوم تكمن في نزوع الناس وتعطشهم لمشاعر واهمة وشعارات براقة تدعوا للحفاظ علي الصحة النفسية. ومع أهمية العنوان، فإن المضمون يختلف بالكلية عما يجب أن يتم لتحقيقه، فتجد اللجوء للطبيب النفسي في كل صغيرة وكبيرة إلي حد الهوس للحفاظ علي التوازن النفسي، ويكأن “التارجت” يكمن في التوازن النفسي، دون حتي أن يتم تعريف واضح لمفهومه.\n\n\nمفهوم الصدمة\nإختلف تعريف الصدمة علي مر العصور طبقًا لمتغيرات كثيرة. عند الرجوع إلي الدليل الإرشادي للإضطرابات النفسية في العالم، نجد أن التعريف قد مر بثلاث تغيرات كبرى. قبيل العام 1980، إقتصر التعريف علي الإضطرابات الناتجة عن الأضرار المادية للجسم مثل إضابة الدماغ الرضية Traumatic Brain Injury.\nتوسع المفهوم في الإصدار الثالث للدليل ليشمل إضطراب ما بعد الصدمة Post-traumatic Stress Disorder ويعتبر هو أول إصابة للصدمة دون ضرر مادي يتم تعريفها، وقد عرفها الدليل آنذاك أنها تجربة عنيفة شديدة الهول يختبرها المريض مثل الحرب والإغتصاب والتعذيب. حدث إنقلاب في هذا المنظور بعيد العام 2000م، حيث تسلل مفهوم إضطراب ما بعد الصدمة ليشمل أى تجربة مر بها الشخص وتسببت في أذي مادي ونفسي ، مع آثار نفسية سلبية ومستديمة علي صحته النفسية والذهنية والشعورية.\nتكمن المشكلة هنا في عدم وجود أى معيار علي أساسه يتم إدراج الشخص تحت مظلة المريض النفسي، بل يرجع التشخيص إلي وصف المريض نفسه لحالته والتي -غالبًا- ما ستكون مشوشة بعض الشئ وغير دقيقة.\nوعلي هذا الأساس فإننا رأينا فرطًا في وصف حالات إنسانية بعينها كالحزن علي أنه اكتئابًا مثلا، وهذا الإفراط يرجع بشكل رئيسى إلي الخلل الذي حدث في تعريف الصدمة والإضطراب النفسي كما ذكرنا سلفًا.\nيتم تشخيص الشخص أنه مصاب بإضطراب الإكتئاب الحاد Major Depressive Disorder عبر ملاحظة خمسة أعراض رئيسية هى (الإحباط، فقدان الإهتمام، نقص الشهية، التغير في النوم، الإرهاق) إذا استمرت لمدة أسبوعين متواصلين. لكن السؤال هنا، ما الذي يجعل هذه العناصر الخمس وحدها مجتمعة معبرة عن الإضطراب النفسي بالتالي تلزمنا بالتدخل العلاجي؟ الإجابة بسيطة لا يوجد دليل قطعي علي صلاحية هذه العناصر لإعطاء استنتاج ختامي بل هو مجرد رأي مجموعة من الناس بلا معايير واضحة. هذه الحالة من التشخيص المفرط للحالات العادية بأنها تعاني من إضطرابات أدى في النهاية إلي\nإذًا ما المشكلة من الإفراط في توصيف هذه الحالات الإنسانية العادية وتضخيمها وإحالتها بالتبعية لمختص نفسي لعلاجها؟ المشكلة أننا نجد موجة من اللجوء إلي شعارات مثل “ الحفاظ علي الصحة النفسية” والتي تحولت إلي هوس هذه الأيام، فتجد الشخص يلهث وراءها حثيثًا من منطلق أنها شئ لا بد منه بل يلوم نفسه علي عدم وصوله لهذه الحالة من “السواء النفسي” دون أن يعطينا أصلًا تعريفًا واضحًا بماذا يقصد بمفهوم “السواء النفسي”.\nالحياة ستعج بالأخطاء دائمًا، والسعادة الحقيقية تشتمل علي الرضا وتقبل الأخطاء ما دامت تبذل أقصي ما في وسعك لتحقيق النجاح، لكن التكالب المتزايد والنزوع إلي الذهاب للطبيب النفسي مع كل صغيرة وكبيرة يؤدي إلي فقدان جوهر المعنى المستفاد من كل صعوبة في الحياة: ما لا يقتلك يجعلك أقوى.\n\n\nنظام الاستتباب والتوازن الداخلي للجسد : Homoestasis\nيتكيف الإنسان مع الصدمات النفسية والمشاكل الحياتية بفضل ما يسمى بنظام التوازن الداخلي للجسد. يعمل جسم الإنسان على الحفاظ علي التوازن الكيميائي والبيولوجي، ويرتبط هذا النظام بقدرة أعضاء جزء الإنسان علي تأدية دورها، ومن ثم، فإن أي تعطيل بهذا النظام يمكن أن يؤدي إلي موت الإنسان نتيجة عدم قدرة الأعضاء علي تأدية دورها.\nكذلك يعمل المخ علي التكيف مع الإضطرابات والصدمات الحياتية، ويقوم كل إنسان طبقًا لميكانيزماته الخاصة في تتبع نمط ما من السلوكيات التي تحاقفظ علي هذا التوازن، فهذا يحب أن يركض، وهذه تحب أن تأكل في مطعم فاخر، وكل هذه ما هي إلا ميكانيزمات وأدوات تختلف من شخص للآخر هدها في النهاية واحد وهو التغلب علي حدث ما في واجه المرء في حياته.\nأما إذا لجأ الإنسان إلي العقاقير الطبية وهو لا يحتاج إليها فإنه قد يعطل نظام التوازن الداخلي للجسد ويجعل الدروس المستفادة من المشاكل اليومية مثل إجراء تغييرات في طريقة المعيشة وإزالة الضغط بممارسة الأنشطة، يجعل كل ذلك معطل.\n\n\nالعلاج: كيف نهرب من دوامة الطب النفسي والعقاقير (حين لا نحتاج إليها)\n\nالبوح: مجرد التنفيس عما بداخلك قد يجعلك في حال أفضل حتي وإن كنت تعتقد أن الكلام لن يحل مشكلتك. فالإنسان مجبول علي حب إخبار الناس بما داخله خصوصًا أشخاصه المقربين. يقول الفقيه ابن عبيد الله السقاف في معني البوح عند ورود النعم مدللًا علي ذلك بذهاب النبي صلي الله عليه وسلم إلي زوجته السيدة خديجة رضي الله عنها يوم نزول الوحي، فقال: ((لا تتجدد لأحد نعمة ، إلا حدثت في صدره ولولة لا تزول عنه، أو يفضي يخبرها إلي أحب الناس إليه )).\nعدم الإستسلام للحزن وإشغال النفس عنه، فكما قال أحمد خالد توفيق في أحد رواياته: ((حل جميع المشاكل النفسية، لاتكن وحيدًا، لا تكن عاطلًا)).\nالأنس بالأهل والأضدقاء ودوائر الدعم القريبة.\nترك مساحة للنفس للتعافي ومعالجة الأمر عن طريق نظام الاستتباب النفسي دون تدخل علاجي."
  },
  {
    "objectID": "posts/non-tech/الهشاشة-النفسية.html#الفصل-الثالث-الفراغ-العاطفي-أم-الفراغ-الوجودي",
    "href": "posts/non-tech/الهشاشة-النفسية.html#الفصل-الثالث-الفراغ-العاطفي-أم-الفراغ-الوجودي",
    "title": "الهشاشة النفسية: إسماعيل عرفة",
    "section": "الفصل الثالث: الفراغ العاطفي أم الفراغ الوجودي؟",
    "text": "الفصل الثالث: الفراغ العاطفي أم الفراغ الوجودي؟"
  },
  {
    "objectID": "posts/ml/homl/chapter-1.html",
    "href": "posts/ml/homl/chapter-1.html",
    "title": "Hands-on Machine learning Chapter 1",
    "section": "",
    "text": "One of the most important books that was written in the field of machine learning ,that is easily accessible to a broad range of audience, is hands-on machine learning. Throughout a series of posts, I will try to explain its main concepts, a chapter by chapter. In this post, the first chapter is explained throughy.\nMachine learning applications are being deployed in all areas. From telecommunications to forecasting, all those applications help business decision making, and daily activities to make a better life. Facebook advertising is one example of such application that is so common to spot among the public. The following table is a summary of some applications:"
  },
  {
    "objectID": "posts/ml/homl/chapter-1.html#what-is-machine-learning",
    "href": "posts/ml/homl/chapter-1.html#what-is-machine-learning",
    "title": "Hands-on Machine learning Chapter 1",
    "section": "What is Machine learning",
    "text": "What is Machine learning\nMachine learning has a long history with different difinitions according to the era. The two most prevalent definitions of machine learning are:\n\nArthur Samuel\n\nField of study that gives computers the ability to learn without being explicitly programmed\n\nTom Mitchell \n\nA computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\n\n\nThe two definitions are quite interesting, but the second one is a little bit more accurate."
  },
  {
    "objectID": "posts/ml/homl/chapter-1.html#types-of-machine-learning",
    "href": "posts/ml/homl/chapter-1.html#types-of-machine-learning",
    "title": "Hands-on Machine learning Chapter 1",
    "section": "Types of Machine learning",
    "text": "Types of Machine learning\nThe following diagram is a concptual representation of the different categories of machine learning algorithms:\n\n\nCategory 1: Method of supervision (Training type)\nIn this category, the idea is to classify the algorithms according to the way they are trained. The two main types are:\n\nSupervised learning\n\nThe algorithm is trained with labeled data. The algorithm learns from the data and tries to predict the label of new data. The two main types of supervised learning are classification and regression.\n\nUnsupervised learning\n\nThe algorithm is trained with unlabeled data. The algorithm tries to find patterns in the data. The two main types of unsupervised learning are clustering and dimensionality reduction.\n\n\n\n\nCategory 2: Method of adaptation\nThis is how the algorithm adapts to new data. The two main types are:\n\nBatch learning\n\nThe algorithm is trained with all the data available. The algorithm is then deployed to production. The algorithm is not trained again unless new data is available.\n\nOnline learning\n\nThe algorithm is trained with a small batch of data. The algorithm is then deployed to production. The algorithm is trained again with new data as it becomes available.\n\n\n\n\nCategory 3: Method of generalization (modeling type)\nThis is how the algorithm generalizes to new data. The two main types are:\n\nInstance-based learning\n\nThe algorithm is trained with labeled data. The algorithm learns from the data and tries to predict the label of new data. The two main types of instance-based learning are classification and regression.\n\nModel-based learning\n\nThe algorithm is trained with labeled data. The algorithm learns from the data and tries to predict the label of new data. The two main types of model-based learning are classification and regression."
  },
  {
    "objectID": "posts/ml/homl/chapter-1.html#main-challenges-in-machine-learning",
    "href": "posts/ml/homl/chapter-1.html#main-challenges-in-machine-learning",
    "title": "Hands-on Machine learning Chapter 1",
    "section": "Main challenges in Machine learning",
    "text": "Main challenges in Machine learning\nWe said that machine learning is a field of study where yoy learn from a training set by describing it using a model. So, we have two things that could go wrong: Data and Model. The following are the two families of things that could go wrong.\n\nData Problems\n\nInsuffiecnt quantity of training data.\n\nThere is an unresonable effect of the quantity of data on the performance of the model. In a study in 2011, it was shown that the performance of a model increases with the quantity of data. The following figure is a representation of the effect of the quantity of data on the performance of the model:\n\nNon-representative training data\n\nYou need your data to be representitve enough for all the cases you want to predict. For example, if you want to predict the price of a house, you need to have data that is representative of the price of the house. If you don’t have data that is representative of the price of the house, you will have a model that is not accurate enough.\n\nPoor-quality data\n\nThe data could be noisy, or it could have missing features. This could happen due to different reasons, for example, the data could be corrupted, or the data could be missing some features or the data collection process resulted in such damage.\n\nIrrelevant features\n\n\n\nModel Problems\n\nOverfitting the training data\nUnderfitting the training data"
  },
  {
    "objectID": "posts/ml/homl/chapter-1.html#testing-and-validation",
    "href": "posts/ml/homl/chapter-1.html#testing-and-validation",
    "title": "Hands-on Machine learning Chapter 1",
    "section": "Testing and validation",
    "text": "Testing and validation\nThe following diagram is a concptual representation of the main challenges in machine learning:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "المدونة",
    "section": "",
    "text": "federated-learning: an introduction\n\n\n\n\n\n\nFederated Learning\n\n\nDeep Learning\n\n\nCommunication\n\n\n\n\n\n\n\n\n\nApr 21, 2023\n\n\nAhmed Khaled\n\n\n\n\n\n\n\n\n\n\n\n\nالهشاشة النفسية: إسماعيل عرفة\n\n\n\n\n\n\nبناء الشخصية\n\n\nمهارات حياتية\n\n\n\n\n\n\n\n\n\nApr 9, 2023\n\n\nAhmed Khaled\n\n\n\n\n\n\n\n\n\n\n\n\nChapter 2: End-to-End Machine Learning Project\n\n\n\n\n\n\nMachine learning\n\n\nHOML\n\n\n\n\n\n\n\n\n\nFeb 14, 2023\n\n\nAhmed Khaled\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Machine learning Chapter 1\n\n\n\n\n\n\nMachine learning\n\n\nHOML\n\n\n\n\n\n\n\n\n\nFeb 10, 2023\n\n\nAhmed Khaled\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Ahmed Khaled, you can call me Ahmed. I am a machine learning engineer and a Research Assistant. I am a Research Assistant at the Intelligent Connectivity and Networks/Systems Group (ICON), Center for Wireless technology (CWC), University of Oulu, Finalnd. I work under the supervision of Prof. Mehdi Bennis. My main area of interests are machine learning, deep learning, Federated Learning, Natural Language Processing, reinforcement learning, and optimization.\nOn the other side of the world, namely the industry, I am a machine learning engineer at Revolution Data Platforms (RDP). RDP is a startup that specializes in building data platforms, data solutions, and anlytical workloads. I am responsible for the development of the machine learning models and the utilization ofLarge Language models(LLMs) to solve customer’s specifc usecases. I mainly work with Azure Cloud, Python, and Pytorch.\nFor more information about my work, please check my CV.\nThis is my personal place on the internet where I create technical and non-technical content, and write about topics that I like and find interesting. I like to write because, first, like it, and second, I can see the gap in my knowledge when I write about something."
  },
  {
    "objectID": "posts/federated-learning/federated.html",
    "href": "posts/federated-learning/federated.html",
    "title": "federated-learning: an introduction",
    "section": "",
    "text": "Federated learning is a very hot topic in the current machine learning spectrum. We can clearly see the word being advertised in many conferences, papers, and even youtube videos and meduim articles. With this hype it’s our duty to dig deeper to understand what is it all about. In this post we will try to understand the concept of federated learning and how it can be applied in real life. My goal is to summarize the technical survey published in 2021 titled Advances and open problems in Federated Learning.\nThe term Federated Learning is not a new sub-field of machine learning (it’s not like deep learning), it’s just a new setting for solving machine learning problems with privacy in mind. The idea is to train a model on a distributed dataset without sharing the data with a central server. This is done by training the model on each client’s data and then aggregating the model parameters to the server. The server then sends the updated model to the clients to continue the training process. This process is repeated until the model converges.\nThe following figure illustrates a very basic federated learning process:\nSo, the basic idea is:\nHaving stated the basic setting of a federated learning problem, we will continue investigating the challenges and open problems in the field, one by one, and try to understand the proposed solutions and current state of the art techniques. we finsih by listing a set of tools and frameworks that can be used to implement federated learning algorithms in practice."
  },
  {
    "objectID": "posts/federated-learning/federated.html#introduction",
    "href": "posts/federated-learning/federated.html#introduction",
    "title": "federated-learning: an introduction",
    "section": "Introduction",
    "text": "Introduction\nThe term Federated Learning was introduce in 2016 bt McMahan et al. The paper defined a set of challenges as the core assumptions of FL systems.\nAlthough the initial work of federated learning focused on cross-device learning, the interest has grown to include what we call cross-silo setting. So, the natural question should be: what are cross-device and cross-silo settings?\n\nCross-device setting: the data is distributed across multiple devices (clients). One example of this is Google Keyboard Gboard, where the data is distributed across multiple mobile devices. The clients here are mobile/edge devices. The data is stored in the messaging app (locally). and the model is trained on the device and the updated model is sent to the server.\nCross-silo setting: the data is distributed across multiple organizations’s servers (silos). This could happen where different hospitals come together to train a model to solve a medical problem without sharing the data with a central server. The clients here are not mobile/edge devices, rather, they are the organization’s servers.\n\n\nThe lifecycle of a model training in Federated learning\n\nClient Selection\nBroadCasting.\nClient Computation.\nAggregation.\nModel Update."
  },
  {
    "objectID": "posts/federated-learning/federated.html#relaxing-the-core-fl-assumptions-emerging-settings-and-scenarios",
    "href": "posts/federated-learning/federated.html#relaxing-the-core-fl-assumptions-emerging-settings-and-scenarios",
    "title": "federated-learning: an introduction",
    "section": "Relaxing the core FL assumptions: Emerging settings and Scenarios",
    "text": "Relaxing the core FL assumptions: Emerging settings and Scenarios\nIn this section, a handful of emerging settings and scenarios are discussed. The goal is to understand the challenges and open problems in each setting and scenario and how they can solve FL problems in such settings.\n\nFully decentralized FL: Peer-to-peer FL"
  },
  {
    "objectID": "posts/ml/homl/chapter-2.html",
    "href": "posts/ml/homl/chapter-2.html",
    "title": "Chapter 2: End-to-End Machine Learning Project",
    "section": "",
    "text": "When starting a new code, try to import all the libraries you gonna need. The function init_session() is here to set the random seed to 42, so that the results are reproducible. It alse enables the warnings to be ignored (because this might be annoying).\nimport random, os, sys\nimport shutil \nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport urllib\n\n\ndef init_session(RANDOM_SEED = 42):\n    RANDOM_SEED = RANDOM_SEED\n    np.random.seed(RANDOM_SEED)\n    random.seed(RANDOM_SEED)\n    import warnings\n    warnings.filterwarnings('ignore')\ninit_session()"
  },
  {
    "objectID": "posts/ml/homl/chapter-2.html#getting-the-data",
    "href": "posts/ml/homl/chapter-2.html#getting-the-data",
    "title": "Chapter 2: End-to-End Machine Learning Project",
    "section": "Getting the data",
    "text": "Getting the data\nFirst things first, you should get the data from the source. This source could be a sensor reading, a database, a website, or a file. In this case, the data is a CSV file. You can download it from the author’s github repository. The function DataFetcher() is here to download the data from the source and return a pandas dataframe. The function takes the source as an argument. The source is the URL of the data. The function checks if the data is already downloaded, if not, it downloads it and returns the dataframe. The function also creates a datasets folder if it doesn’t exist.\n\ndef DataFetcher(*, source):\n\n    file_name = Path(source).name #housing.tgz\n    compressed_path = Path(os.path.join(\"datasets\", file_name))#datasets/housing.tgz\n    compressed_dir = str(compressed_path).split(\".\")[-2]#datasets/housing\n\n    if not compressed_path.is_file():\n        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n        urllib.request.urlretrieve(source, compressed_path)\n        shutil.unpack_archive(compressed_path, os.path.join(\"datasets\"))\n    return pd.read_csv(os.path.join(compressed_dir, file_name.split(\".\")[-2] + \".csv\"))\n\n\nNote\n\nYou can notice the * being passed before the source as the first parameter. In fact this is not a parameter but it’s a feature in python &gt;= 3.8 that makes the function take only keyword arguments. This is to make sure that the function is called with the source argument to avoid confusion when calling the function. In short, this enforces you to call all the function’s parameters after * using keyword arguments.\n\n\nNow you can call the function like this:\n\nurl = \"https://github.com/ageron/data/raw/main/housing.tgz\"\nhousing = DataFetcher(source= url)\n\nhousing is now a dataframe. You can check this using:\n\ntype(housing)\n\nNow, you can take a look at the data using the head() method. This method returns the first 5 rows of the dataframe. You can also pass the number of rows you want to see as an argument.\n\nhousing.head()\n\nAnother handy function to summarize your data is the info() method. This method returns the number of rows, the number of columns, the column names, the data type of each column, and the number of non-null values in each column.\n\nhousing.info()\n\nYou can also see the Dtype column in the output of the info() method. This column shows the data type of each column. You can see that the ocean_proximity column is an object. This means that it’s a string. You can check the unique values of this column using the unique() method.\n\nhousing.ocean_proximity.unique()\n\nor you can use the value_counts() method to get the number of instances of each value.\n\nhousing.ocean_proximity.value_counts()\n\nSince most columns (Also called features, dependent variable, predictors, attributes) are numerical, you can use the describe() method to get the summary of the numerical columns. This is quite useful to get a quick overview of the data. We can see that this is literally a sumaary of statistics. The count, mean, std, min, max, and the percentiles AKA descriptive statistics.\n\nhousing.describe()\n\n\nCreating a Test Set OR Sampling 101\nAfter you get the data, you should keep a test set aside, this test set is used to evaluate the performance of your model. There are different ways to assess the quality of your test set. One such metric is the representativeness of it, which means that your test set should resemble the original data as much as possible. The test set should be kept aside until the end of the project to avoid the data snooping bias.\nSo, what is The data snooping bias? It is when you look at the test set and you tweak your model to perform better on the test set. This is not a good practice because you are not supposed to look at the test set until the end of the project.\nThere is a saying in statistics:\n    Torture the data until it confesses.\nThis is quite the same thing you ar doing here. You are tweaking the performance on a test set until it confesses. This is not a good practice. As a gneral rule, the test set is used to evaluate the performance of your model, not to tweak it. So, you should keep it aside until the end of the project.\nSo, the question is how to choose a test set. On can split the data selectively, for example, you can choose the last 20% of the data as the test set. This is not a good practice because:\n\nif you add new data, the last 20% of the data will change. So, you should not use this method. (your test result is not reproducible).\nIf your data is not evenly distributed, you might be trabbed in selective bias. For example, if you have a dataset of 1000 instances and 20% of them are from California, and for your case those 200 instances are the last 200 instances in your data. The result is you will have 200 instances from California in the test set and no other data from anywhere else. This is not a good practice because you will have a biased test set. (non-representativeness of the test set).\n\nThe last reason is an example of a phenomenon called Sampling Bias,one form of a bigger term Selection Bias, which refers to a falw in the process of choosing the data. Sampling Bias is a selection bias in the process of sampling a subset (sample) from the original data (the population).\nThere are many ways to sample a subset from the original data. The most common ones are:\n\nSimple Random Sampling\nStratified Random Sampling\nSystematic Random Sampling\nCluster Sampling\nMultistage Sampling\n\nThe first two are of interest for us in this chapter. So let us start by the simplest case, the simple random sampling.\n\nSimple Random Sampling\nThis process is quite simple. You just randomly select a subset of the data. This is the simplest way to sample a subset from the original data. You can do the following to sample a subset from the original data:\n\nShuffle the data based on the index.\n\nnp.random.permutation(len(data)) will return a list of indices of the data shuffled.\n\nDefine the size of the test set. You can specify a ration (0.2) and multiply it by the length of the data.\n\nint(len(data) * test_ratio) will return the size of the test set.\n\nGenerate two list of the indices; one for the training set and one for the test set.\n\ntest_indices = shuffled_indices[:test_set_size] will return the indices of the test set.\ntrain_indices = shuffled_indices[test_set_size:] will return the indices of the training set.\n\nUse the indices to select the data from the original data.\n\ndata.iloc[train_indices] will return the training set dataframe.\ndata.iloc[test_indices] will return the test set dataframe.\n\nThis works because train_indices is a list of integers, and the iloc method takes a list of integers as an argument and returns the corresponding rows.\n\nThe following code illustrates the process of simple random sampling:\n\nimport numpy as np\n\ndef shuffle_and_split_data(data, test_ratio):\n    np.random.seed(42)\n    shuffled_indices = np.random.permutation(len(data))\n    test_set_size = int(len(data) * test_ratio)\n    test_indices = shuffled_indices[:test_set_size]\n    train_indices = shuffled_indices[test_set_size:]\n    return data.iloc[train_indices], data.iloc[test_indices]\n\nThere are a problem with this approach:\n\nIf you run the program again, it will generate a different test set! Over time, you will get to see the whole dataset (data snooping bias again!!!), which is what we want to avoid.\n\nWe can mitigate this problem by one of the following solutions:\n\nSave the test set on the first run and then load it in subsequent runs.\n\nThe problem here is that, loading the test set every time is a waste of time and space. So, you should only do this if the dataset is quite small.\n\nSet the random number generator’s seed (e.g., np.random.seed(42) before calling np.random.permutation()) so that it always generates the same shuffled indices.\n\nThis could be tricky to understand why this solution is not perfect. So, let us try it:\n\n\n\ntrain_1, test_1 = shuffle_and_split_data(housing, 0.2)\n\n- Now, let us run the code again:\n\nhousing = DataFetcher(source=url)\ntrain_2, test_2 = shuffle_and_split_data(housing, 0.2)\n\nprint(train_1.equals(train_2))\ntest_1.equals(test_2)\n\n\nUse each instance’s identifier to decide whether or not it should go in the test set (assuming instances have a unique and immutable identifier). For example, you could compute a hash of each instance’s identifier, keep only the last byte of the hash, and put the instance in the test set if this value is lower or equal to 51 (256 * 0.2 = 51.2). This ensures that the test set will remain consistent across multiple runs, even if you refresh the dataset. The new test set will contain 20% of the new instances, but it will not contain any instance that was previously in the training set.\n\n\n\nStratified Random Sampling\nThe following image illustrates the process of stratified random sampling:\n\n\n\nstratified random sampling"
  },
  {
    "objectID": "posts/ml/homl/chapter-2.html#exploring-the-data",
    "href": "posts/ml/homl/chapter-2.html#exploring-the-data",
    "title": "Chapter 2: End-to-End Machine Learning Project",
    "section": "Exploring the data",
    "text": "Exploring the data\nNext stage is to gain some insights by looking at your data. This is one of the most important steps in the machine learning pipeline. The effect of this step is that it will unlock some structure in the data, like the outliers, the missing values, the noise, and the correlation between the features. This will help you in the next steps of the pipeline.\nWe shall start by visualizing the distribution of the features. This is done by plotting the histogram of each feature. The hist() method is used to plot the histogram. The bins argument is used to specify the number of bins. The figsize argument is used to specify the size of the figure. The plt.show() is used to display the figure.\n\n\n\nhousing.hist(bins=50, figsize=(10,8))\nplt.tight_layout()\nplt.show()\n\n\nFigure 1\n\n\n\nFigure 1 is a histogram of the numerical features. We will dive into the kind of visualization that we should use according to the data type and the task in a separate blog post. For now, we can say that for numerical features, hisograms are the most suitable visualization type to use."
  }
]